{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "alone-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score,fbeta_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fatty-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(\"data.csv\", dtype = {'desc':str,'next_paymnt_d':object,'verification_status_joint':str})\n",
    "#DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "large-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy variables for 3 of my cateragorical features \n",
    "Loan_grade = pd.get_dummies(DF['grade'])\n",
    "Home_type = pd.get_dummies(DF['home_ownership'])\n",
    "term = pd.get_dummies(DF['term'])\n",
    "# creating Dummies data frame \n",
    "Dummy = pd.concat([Loan_grade,Home_type,term],axis=1)\n",
    "DummyUse = Dummy[['E','F','G','RENT','MORTGAGE',' 60 months']]\n",
    "# creating numerical data frame \n",
    "NumericalUse = DF[['id','loan_amnt','int_rate','annual_inc','default_ind']]\n",
    "\n",
    "# creating my feature/target space data frame \n",
    "Features = pd.concat([DummyUse,NumericalUse],axis=1)\n",
    "COLS = Features.columns\n",
    "#sns.pairplot(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "disabled-polish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.kdeplot(data=DF, x=\"loan_amnt\", hue=\"default_ind\", multiple=\"stack\")\n",
    "\n",
    "ax = sns.kdeplot(data=Features, x='annual_inc', hue=\"default_ind\", multiple=\"stack\")\n",
    "ax.set_xlim(10000,200000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "nutritional-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining feature space and target space for logestic model\n",
    "X= Features.iloc[:,0:len(COLS)-1]\n",
    "y = Features.iloc[:,len(COLS)-1:len(COLS)]\n",
    "\n",
    "# splitting data , setting aside 20% for testing\n",
    "X_x, X_test, Y_y, y_test  = train_test_split(X, y, test_size = 0.20, random_state=5)\n",
    "# creating a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_x,Y_y, test_size = .25, random_state = 57)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-throw",
   "metadata": {},
   "source": [
    "# Precision and Recall Using KNN\n",
    "1. Only takes 20,000 data points, otherwise would be too slow \n",
    "2. Find K value that gives best accuracy\n",
    "3. Precision and recall still zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "interesting-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_K(X,y):\n",
    "    ks = list(range(1, 70))\n",
    "    K_scores = []\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "        K_scores.append(scores.mean())\n",
    "    Max_Score = max(K_scores)\n",
    "    K_value = K_scores.index(max(K_scores))\n",
    "\n",
    "    return K_scores,ks, Max_Score, K_value\n",
    "\n",
    "def plot_K(K1,K0,K2,K3):\n",
    "    plt.plot(K1, K0)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "\n",
    "    print('KFold Cross Validation: ',K2)\n",
    "    print('When K is: ',K3)\n",
    "\n",
    "\n",
    "def fit_predict_scoreKNN(X,Y,x,y,k):\n",
    "  \n",
    "    #instantiating\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #fitting \n",
    "    knn.fit(X.iloc[:20000,1:len(COLS)-1], Y.iloc[:20000])\n",
    "    \n",
    "    # predicting \n",
    "    y_predict = knn.predict(x.iloc[:20000,1:len(COLS)-1])\n",
    "   \n",
    "    \n",
    "    FB = fbeta_score(y_predict,Y.iloc[:20000], average='macro', beta=0.70)\n",
    "    Recall = recall_score(Y.iloc[:20000],y_predict)\n",
    "    Precision = precision_score(Y.iloc[:20000],y_predict)\n",
    "\n",
    "    return FB, Recall, Precision \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "green-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling functions for KNN\n",
    "#K = choose_K(X.iloc[:20000,1:],y.iloc[:20000])\n",
    "#plot_K(K[1],K[0],K[2],K[3])\n",
    "fit_predict_scoreKNN(X_train,y_train,X_val,y_val,67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-result",
   "metadata": {},
   "source": [
    "#  Defining Functions for use in Logistic Regression Analysis \n",
    "1. Fit model, Predict using different models, Score using different models \n",
    "2. all 'models' are just different versions of logestic regression \n",
    "3. Cash flow function is for buisness analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "retired-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_scoreLOGREG(X,Y,x,y):\n",
    "    # X,Y are for fitting \n",
    "    # x,y are for predicting and scoring\n",
    "    # instantiating models\n",
    "    lr = LogisticRegression(solver='liblinear')\n",
    "    lr_balanced = LogisticRegression(class_weight = 'balanced',solver = 'liblinear')\n",
    "    lr_Xx = LogisticRegression(class_weight= {1:10, 0:1}, solver='liblinear')\n",
    "    \n",
    "    # fitting models to data set aside in train/test split\n",
    "    lr.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "    lr_balanced.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "    lr_Xx.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "\n",
    "    # predict for base and weights \n",
    "    y_predictW = lr_Xx.predict(x.iloc[:,1:len(COLS)-1])\n",
    "    y_predictBase = lr.predict(x.iloc[:,1:len(COLS)-1])\n",
    "\n",
    "    # scoring models on validation set \n",
    "    F1B_score = f1_score(y, lr_balanced.predict(x.iloc[:,1:len(COLS)-1]))\n",
    "    F1Xx_score = f1_score(y, lr_Xx.predict(x.iloc[:,1:len(COLS)-1]))\n",
    "    AccuracyReg = lr.score(x.iloc[:,1:len(COLS)-1],y)\n",
    "    AccuracyWeight = lr_Xx.score(x.iloc[:,1:len(COLS)-1],y)\n",
    "    FBb = fbeta_score(lr_balanced.predict(x.iloc[:,1:len(COLS)-1]),y, average='macro', beta=0.70)\n",
    "    FBW = fbeta_score(lr_Xx.predict(x.iloc[:,1:len(COLS)-1]),y, average='macro', beta=0.70)\n",
    "    FBbase = fbeta_score(y_predictBase,y, average = 'macro', beta=.70)\n",
    "    RecallB = recall_score(y,y_predictBase)\n",
    "    PrecisionB = precision_score(y,y_predictBase)\n",
    "    RecallW = recall_score(y,y_predictW)\n",
    "    PrecisionW = precision_score(y,y_predictW)\n",
    "    \n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    y_predict = (lr_Xx.predict_proba(x.iloc[:,1:len(COLS)-1])[:,1] >= .50)\n",
    "    default_confusion = confusion_matrix(y, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(default_confusion, cmap=plt.cm.Blues, annot=True, square=True, fmt='d',\n",
    "            xticklabels=['NoDefault', 'Default'],\n",
    "            yticklabels=['NoDefault', 'Default']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "    \n",
    "    return F1B_score,F1Xx_score,FBb,FBW,FBbase,RecallB,PrecisionB,RecallW,PrecisionW \n",
    "\n",
    "def format_scores(A,B,C,D,E,F,G,H,I):\n",
    "    # F1 Scores \n",
    "    print('Balanced class weights Logistic Regression Test F1:', A)\n",
    "    print('20:1 class weights Logistic Regression Test F1: ', B)\n",
    "    print(\"\")\n",
    "\n",
    "    # FBeta Scores\n",
    "    print(\"FBeta Score Stock: \",E )\n",
    "    print('FBeta Score Balanced: ', C)\n",
    "    print('FBeta Score weights: ',D)\n",
    "    print(\"\")\n",
    "    \n",
    "    #Recall \n",
    "    print('Recall Score No weights: ',F)\n",
    "    print('Recall Score weighted: ',H)\n",
    "    print(\"\")\n",
    "\n",
    "    #Precision\n",
    "    print('Precision Score No weights: ',G)\n",
    "    print('Precision Score weighted: ',I)\n",
    "    print(\"\")\n",
    "    \n",
    "def make_confusion_matrix(model, threshold):\n",
    "    # Predict class 1 if probability of being in class 1 is greater than threshold\n",
    "    y_predict = (model.predict_proba(X_test.iloc[:,1:len(COLS)-1])[:,1] >= threshold)\n",
    "    default_confusion = confusion_matrix(y_test, y_predict)\n",
    "    plt.figure(dpi=80)\n",
    "    sns.heatmap(default_confusion, cmap=plt.cm.Blues, annot=True, square=True, fmt='d',\n",
    "            xticklabels=['NoDefault', 'Default'],\n",
    "            yticklabels=['NoDefault', 'Default']);\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('actual')\n",
    "\n",
    "def hard_soft(X_test):\n",
    "    # hard and soft classification results for weighted logistic regression\n",
    "    HardClassificationXx = lr_Xx.predict(X_test.iloc[:,1:len(COLS)-1])\n",
    "    SoftClassificationXx = lr_Xx.predict_proba(X_test.iloc[:,1:len(COLS)-1])\n",
    "    SoftClassificationReg = lr.predict_proba(X_test.iloc[:,1:len(COLS)-1])\n",
    "    # putting into data frames for plotting in seaborn\n",
    "    return HardClassificationXx,SoftClassificationXx,SoftClassificationReg\n",
    "\n",
    "def convert_to_hard(SCXx):\n",
    "    # for threshold of .39\n",
    "    HardClass = []\n",
    "    SC = SCXx.tolist()\n",
    "    for item in SC:\n",
    "        if item[1] > .39:\n",
    "            HardClass.append(1)\n",
    "        else:\n",
    "            HardClass.append(0)\n",
    "    return HardClass\n",
    "\n",
    "def make_cashflow_df(HCXx,X,df):\n",
    "    PREDICT = pd.DataFrame(HCXx, columns = {'Predict'})\n",
    "    i_d = X['id']\n",
    "    ID = pd.DataFrame(i_d)\n",
    "    ID.reset_index(drop=True,inplace=True)\n",
    "    PredId = pd.concat([ID,PREDICT],axis=1)\n",
    "    MONEYLOST = DF[['id','loan_amnt','total_rec_prncp','total_rec_int','default_ind']]\n",
    "    MONEY = pd.merge(left=PredId, right=MONEYLOST, left_on='id', right_on='id')\n",
    "    MONEY.dropna(inplace=True)\n",
    "    return MONEY\n",
    "\n",
    "def make_mask(df):\n",
    "    maskA = df['default_ind'] == 0\n",
    "    maskB = df['default_ind'] == 1\n",
    "    CASH = df[maskA]\n",
    "    CASH2 = df[maskB]\n",
    "    return CASH, CASH2\n",
    "\n",
    "def cash_flow(CASH,CASH2):\n",
    "    RANGE = RecallSpace.shape\n",
    "    Saved = []\n",
    "    Lost = []\n",
    "    made = []\n",
    "    walked = []\n",
    "    for i in range(100):\n",
    "        if (CASH['Predict'].iloc[i] == 0.0) and (CASH['default_ind'].iloc[i] == 1.0):\n",
    "            Amount_lost = CASH['loan_amnt'].iloc[i] - (CASH['total_rec_prncp'].iloc[i] + CASH['total_rec_int'].iloc[i])\n",
    "            Lost.append(Amount_lost)\n",
    "        if (CASH['Predict'].iloc[i] == 1.0) and (CASH['default_ind'].iloc[i] == 1.0):\n",
    "            Amount_saved = CASH['loan_amnt'].iloc[i]\n",
    "            Saved.append(Amount_saved)\n",
    "        \n",
    "        if (CASH2['Predict'].iloc[i] == 0.0) and (CASH2['default_ind'].iloc[i] == 0.0):\n",
    "            Amount_made = CASH2['loan_amnt'].iloc[i] + (CASH2['loan_amnt'].iloc[i]*.08)\n",
    "            made.append(Amount_made)\n",
    "                                                     \n",
    "        if (CASH2['Predict'].iloc[i] == 1.0) and (CASH2['default_ind'].iloc[i] == 0.0):\n",
    "            Amount_lost = CASH2['loan_amnt'].iloc[i] + (CASH2['loan_amnt'].iloc[i]*.08)\n",
    "            walked.append(Amount_lost)\n",
    "    Made_total = sum(made)\n",
    "    Walked_total = sum(walked)\n",
    "    Saved_Total = sum(Saved)\n",
    "    Lost_Total = sum(Lost)\n",
    "    return Made_total, Walked_total,Saved_Total,Lost_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "judicial-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling functions \n",
    "VAL = fit_predict_scoreLOGREG(X_train,y_train,X_val,y_val)\n",
    "TEST = fit_predict_scoreLOGREG(X_x,Y_y,X_test,y_test)\n",
    "print(\"-----VALIDATION-----\")\n",
    "VALIDATE = format_scores(VAL[0],VAL[1],VAL[2],VAL[3],VAL[4],VAL[5],VAL[6],VAL[7],VAL[8])\n",
    "print(\"-----TEST-----\")\n",
    "TESTED = format_scores(TEST[0],TEST[1],TEST[2],TEST[3],TEST[4],TEST[5],TEST[6],TEST[7],TEST[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-royal",
   "metadata": {},
   "source": [
    "# Calling Cash Flow Functions \n",
    "1. Hard and soft classifications\n",
    "2. Make a cash flow data frame\n",
    "2. Seperate all actual positive and negative class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "headed-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "HCSC = hard_soft(X_test)\n",
    "MNY = make_cashflow_df(HCSC[0],X_test,DF)\n",
    "Csh = make_mask(MNY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-spouse",
   "metadata": {},
   "source": [
    "# Decision Trees \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "promotional-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "def fit_predict_scoreDT(X,Y,x,y):\n",
    "    weights = {1:20, 0:1}\n",
    "    dtb = DecisionTreeClassifier(class_weight = 'balanced',max_depth=10)\n",
    "    wdt = DecisionTreeClassifier(class_weight=weights,max_depth=10)\n",
    "    dt = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "    dtb.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "    wdt.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "    dt.fit(X.iloc[:,1:len(COLS)-1], Y)\n",
    "    \n",
    "    y_predictW = wdt.predict(x.iloc[:,1:len(COLS)-1])\n",
    "    y_predictBase = dt.predict(x.iloc[:,1:len(COLS)-1])\n",
    "    \n",
    "    F1B_score = f1_score(y, dtb.predict(x.iloc[:,1:len(COLS)-1]))\n",
    "    F1Xx_score = f1_score(y, wdt.predict(x.iloc[:,1:len(COLS)-1]))\n",
    "    AccuracyReg = dt.score(x.iloc[:,1:len(COLS)-1],y)\n",
    "    AccuracyWeight = wdt.score(x.iloc[:,1:len(COLS)-1],y)\n",
    "    FBb = fbeta_score(dtb.predict(x.iloc[:,1:len(COLS)-1]),y, average='macro', beta=0.70)\n",
    "    FBW = fbeta_score(wdt.predict(x.iloc[:,1:len(COLS)-1]),y, average='macro', beta=0.70)\n",
    "    FBbase = fbeta_score(y_predictBase,y, average = 'macro', beta=.70)\n",
    "    RecallB = recall_score(y,y_predictBase)\n",
    "    PrecisionB = precision_score(y,y_predictBase)\n",
    "    RecallW = recall_score(y,y_predictW)\n",
    "    PrecisionW = precision_score(y,y_predictW)\n",
    "    \n",
    "    return F1B_score,F1Xx_score,FBb,FBW,FBbase,RecallB,PrecisionB,RecallW,PrecisionW \n",
    "\n",
    "def format_scores(A,B,C,D,E,F,G,H,I):\n",
    "    # F1 Scores \n",
    "    print('Balanced class weights Trees Test F1:', A)\n",
    "    print('20:1 class weights Trees F1: ', B)\n",
    "    print(\"\")\n",
    "\n",
    "    # FBeta Scores\n",
    "    print(\"FBeta Score Stock: \",E )\n",
    "    print('FBeta Score Balanced: ', C)\n",
    "    print('FBeta Score weights: ',D)\n",
    "    print(\"\")\n",
    "    \n",
    "    #Recall \n",
    "    print('Recall Score No weights: ',F)\n",
    "    print('Recall Score weighted: ',H)\n",
    "    print(\"\")\n",
    "\n",
    "    #Precision\n",
    "    print('Precision Score No weights: ',G)\n",
    "    print('Precision Score weighted: ',I)\n",
    "    print(\"\")\n",
    "                                 \n",
    "                                \n",
    "VALTREE = fit_predict_scoreDT(X_train,y_train,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "collect-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALTREE = fit_predict_scoreDT(X_train,y_train,X_val,y_val)\n",
    "TESTTREE = fit_predict_scoreDT(X_x,Y_y,X_test,y_test)\n",
    "print(\"-----VALIDATION-----\")\n",
    "VALIDATE = format_scores(VALTREE[0],VALTREE[1],VALTREE[2],VALTREE[3],VALTREE[4],VALTREE[5],VALTREE[6],VALTREE[7],VALTREE[8])\n",
    "print(\"-----TEST-----\")\n",
    "TESTED = format_scores(TESTTREE[0],TESTTREE[1],TESTTREE[2],TESTTREE[3],TESTTREE[4],TESTTREE[5],TESTTREE[6],TESTTREE[7],TESTTREE[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-resort",
   "metadata": {},
   "source": [
    "# Exploring log loss \n",
    "1. try calculating 'by hand' \n",
    "2. Use built in \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "surrounded-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try and interpret log loss \n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def LOGLOSS(model,X_test,y_test):\n",
    "    HardClassificationXx = model.predict(X_test.iloc[:,1:len(COLS)-1])\n",
    "    SoftClassificationXx = model.predict_proba(X_test.iloc[:,1:len(COLS)-1])\n",
    "    ProbPos = [SoftClassificationXx[i][1] for i in range(len(SoftClassificationXx))]\n",
    "    PosProb = pd.DataFrame(ProbPos,columns = {\"Prob in Pos Class\"})\n",
    "    HardPred = pd.DataFrame(HardClassificationXx, columns = {'Predicted Hard'})\n",
    "    y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    LogLoss = pd.concat([PosProb,HardPred,y_test],axis=1)\n",
    "    return LogLoss\n",
    "\n",
    "LLWeights = LOGLOSS(lr_Xx,X_test,y_test)\n",
    "LLStock = LOGLOSS(lr,X_test,y_test)\n",
    "LL1 = log_loss(y_test,lr.predict_proba(X_test.iloc[:,1:len(COLS)-1]))\n",
    "LL2 = log_loss(y_test,lr_Xx.predict_proba(X_test.iloc[:,1:len(COLS)-1]))\n",
    "print(\"Log Loss Stock Logistic Regression: \", LL1)\n",
    "print(\"Log Loss Weighted Logistic Regression: \",LL2)\n",
    "\n",
    "LLStock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-productivity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
